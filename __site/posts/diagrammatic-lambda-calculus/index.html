<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
   <link rel="stylesheet" href="/libs/katex/katex.min.css">
     
  
  <link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/poole_hyde.css">
<!-- style adjustments -->
<style>
  html {font-size: 17px;}
  .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;}
  @media (min-width: 940px) {
    .franklin-content {width: 100%; margin-left: auto; margin-right: auto;}
  }
  @media (max-width: 768px) {
    .franklin-content {padding-left: 6%; padding-right: 6%;}
  }
</style>
<!-- <link rel="icon" href="/assets/favicon.png"> -->

   <title>String diagrams for the lambda-calculus?</title>  
</head>
<body>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1><a href="/">Robin Piedeleu</a></h1>
      <p class="lead"></p>
    </div>
    <nav class="sidebar-nav">
      <a class="sidebar-nav-item " href="/">About</a>
      <a class="sidebar-nav-item " href="/research/">Research</a>
      <a class="sidebar-nav-item " href="/blog/">Notes</a>
    </nav>
  </div>
</div>
<div class="content container">

<!-- Content appended here -->
<div class="franklin-content"><h1 id="string_diagrams_for_the_lambda-calculus"><a href="#string_diagrams_for_the_lambda-calculus" class="header-anchor">String diagrams for the \(\lambda\)-calculus?</a></h1>
<p>A few days ago, on twitter, <a href="https://twitter.com/davidad/status/1450417170375135234">Davidad re-discovered</a> a well-known graphical representation for terms of the \(\lambda\)-calculus, sometimes called sharing graphs or interaction nets. These graphical encodings of the \(\lambda\)-calculus have been the object of intense research for a long time. While it&#39;s not my area, I replied with a few tweets explaining some of the trade-offs of this approach as I saw it–from afar, admittedly. I concluded warning that these graphs are not usually understood as string diagrams, even if it is a natural question to ask: <strong>can we find a symmetric monoidal category for which they are genuine string diagrams?</strong> Crucially, can we do so in a way that respects the dynamic aspects of the \(\lambda\)-calculus, <em>i.e.</em> such that the graph-rewriting rules implementing \(\beta\)-reduction are valid equations in the underlying category?</p>
<p>This post gives one possible &#40;<em>spoiler:</em> positive&#41; answer to this question. It has the additional benefit of highlighting some of the issues that arise with copying/sharing of subterms during reduction. But before we get started, a word of warning: it is entirely possible that I am reinventing the wheel and I would love for someone to point me to the relevant papers if that is the case&#33;</p>
<p><em>Prerequisites.</em> In this note, I assume familiarity with string diagrams, monoidal categories, and basic facts about the \(\lambda\)-calculus. To brush up on the first topic, <a href="https://arxiv.org/abs/0908.3347">Peter Selinger&#39;s survey</a> is a safe reference. </p>
<div class="franklin-toc"><ol><li><a href="#relational_profunctors">Relational profunctors</a></li><li><a href="#application_and_abstraction_as_adjoints">Application and abstraction as adjoints</a></li><li><a href="#copying_and_discarding">Copying and discarding</a></li><li><a href="#putting_it_all_together">Putting it all together</a></li><li><a href="#the_problem_with_copying">The problem with copying</a></li><li><a href="#what_is_x">What is \(X\)?</a></li></ol></div>
<h2 id="relational_profunctors"><a href="#relational_profunctors" class="header-anchor">Relational profunctors</a></h2>
<p>First, we need a symmetric monoidal category in which to interpret our diagrams. This will be the category of <em>relational profunctors</em>. While profunctors can be scary, relational profunctors are their friendlier, decategorified cousins. The category of relational profunctors has preordered sets as objects and monotone relations \(R\subseteq X\times Y\) as morphisms \(X\rightarrow Y\). A relation is monotone if whenever \((x,y)\in R\) and \(x'\leq x\), \(y \leq y'\) then \((x',y')\in R\). Composition in this category is the usual composition of binary relations, given by \(R;S = \{(x,z) \,:\, \exists y.\, (x,y)\in R \land (y,z)\in S\}\), which we write in diagrammatic order. The identity on a preorder is none other than the order relation itself&#33;</p>
<p>With the usual product of preorders – the cartesian product of sets with the order on pairs given by \((x,y)\leq (x',y')\) iff \(x\leq x'\) and \(y\leq y'\) – this category is symmetric monoidal, with unit for the monoidal product the singleton set \(1\) with the only possible order. Great – we have a canvas on which to draw string diagrams. In fact, it is a particularly nice setting because relational profunctors form a <em>compact closed</em> category: each object \(X\) has a dual \(X^{op}\) with the same underlying set but the opposite ordering, and there are arrows </p>
<div class="center"><img src="/assets/img/cup.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/>\(: 1 \rightarrow X\times X^{op}\) and <img src="/assets/img/cap.jpg" style="padding:0;display:inline;width: 4.5%;vertical-align:top;" alt=""/>\(: X^{op}\times X\rightarrow 1\)</div>
<p>satisfying the following intuitive equations<sup id="fnref:1"><a href="#fndef:1" class="fnref">[1]</a></sup> :</p>
<div class="center"><img src="/assets/img/snake_eqs.jpg" style="padding:0;display:inline;width: 57%;vertical-align:middle;" alt=""/></div>
<p>An upward flowing wire denotes &#40;the identity on&#41; \(X\), while a downward flowing wire denotes &#40;the identity on&#41; \(X^{op}\). The two equalities above relate an object to its dual and, diagrammatically, give us the ability to bend and straighten wires at will, as long as we preserve the overall directional flow<sup id="fnref:2"><a href="#fndef:2" class="fnref">[2]</a></sup> and the connectivity of the different components.</p>
<div class="warning"><em>Warning for the categorically minded reader.</em> The product of preorders is the categorical product in the category of preorders and monotone <em>maps</em> but does not satisfy the corresponding universal property for relational profunctors &#40;aka monotone <em>relations</em>&#41;. In fact, a compact closed category for which the monoidal product is the categorical product is necessarily a preorder, so the two properties are incompatible in this specific sense.</div>
<h2 id="application_and_abstraction_as_adjoints"><a href="#application_and_abstraction_as_adjoints" class="header-anchor">Application and abstraction as adjoints</a></h2>
<p>In order to interpret our diagrams as relational profunctors, we first fix a single object – a preordered set \(X\) – equipped with a binary operation <img src="/assets/img/app.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/>\(: X\times X \rightarrow X\). Note that we do not require that this relation be associative. You can think of \(X\) as a preordered set containing \(\Lambda\), the set of &#40;closed&#41; \(\lambda\)-terms ordered by the reflexive and transitive closure of \(\rightarrow_\beta\). In this particular case, you can take <img src="/assets/img/app.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> to be any monotone binary relation that restricts over \(\Lambda\) to &#40;the graph of&#41; application of \(\lambda\)-terms, \(\{((u,v),t) : uv \rightarrow^*_\beta t\}\). But we will prefer to work axiomatically, without committing to any specific model, simply requiring properties of \(X\) as we need them. In fact, one reason we do not simply take \(X=\Lambda\) is that we need our model to be better behaved than \(\Lambda\), so we enlarge it to get the desired properties.  </p>
<p>One of the reasons we chose to work with relational profunctors is that we can also ask for the existence of <em>adjoints</em> where we need them. </p>
<div class="remark"><p><strong>Definition.</strong> <em>&#40;Adjunction for relational profunctors&#41;</em> We say that \(R: X\rightarrow Y\) is <em>left adjoint</em> to \(S: Y\rightarrow X\) iff </p>
<a id="adjoints" class="anchor"></a>\[  \quad S ; R \subseteq id_Y \text{and} \quad R ; S \subseteq id_X\]
<p>where \(\subseteq\) denotes the inclusion of relations, seen as subsets.</p></div>
<p>To interpret abstraction we need a right adjoint to <img src="/assets/img/co-abs.jpg" style="padding:0;display:inline;width: 6%;vertical-align:middle;" alt=""/> that we draw as <img src="/assets/img/abs.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/>.  Where does the adjunction come from? We can just postulate it as an axiom or, in the concrete example where \(\Lambda \subseteq X\) above, we can also ask that \(X\) be a complete &#40;semi-&#41;lattice; then, if <img src="/assets/img/app.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> also preserves joins in both arguments, we can define <img src="/assets/img/abs.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> as \(\{((v,u),t) : v/u \leq t\}\) with \(v/u\) given by \(\bigvee\{t : tu \leq v\}\). Intuitively, for terms \(u\) and \(v\), this is the least upper bound of all terms that reduce to \(v\), when applied to \(u\). This may take us outside of \(\Lambda\) and this is why we need an \(X\) with a bit more leg room. The adjunction then follows from the equivalence \(tu\leq v \Leftrightarrow t\leq v/u\).</p>
<p>We now have enough machinery to encode <em>linear</em> \(\lambda\)-terms diagrammatically. By linear, I mean any term that uses each variable exactly once in its body. The translation is straightforward: linear terms are just trees of abstraction and application nodes, with <img src="/assets/img/cup.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> at the bottom joining the wire indicating where a variable is applied to the wire indicating where it is captured by an abstraction:</p>
<div class="center"><img src="/assets/img/linear-encodings.jpg" style="padding:0;display:inline;width: 55%;vertical-align:middle;" alt=""/></div>
<p>All closed linear terms become arrows of type \(1\rightarrow X\); pictorially, diagrams with a single output wire at the top. We can translate open terms in the same way, leaving free variables as input wires at the bottom. </p>
<p>What about \(\beta\)-reduction? This is taken care of by one direction of the adjunction between <img src="/assets/img/co-abs.jpg" style="padding:0;display:inline;width: 6%;vertical-align:middle;" alt=""/> and <img src="/assets/img/abs.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/>. Following <span class="eqref">(<a href="#adjoints">1</a>)</span>, the first inclusion becomes:</p>
<div class="center"><img src="/assets/img/adjunction-abs-coabs.jpg" style="padding:0;display:inline;width: 27%;vertical-align:middle;" alt=""/> or, equivalently, <img src="/assets/img/beta-reduction.jpg" style="padding:0;display:inline;width: 50%;vertical-align:middle;" alt=""/><a id="equation_beta-reduction" class="anchor"></a></div>
<p>To see the connection with \(\beta\)-reduction more clearly, let&#39;s apply it to a redex of the form \((\lambda x.t)u\):</p>
<div class="center"><img src="/assets/img/beta-reduction-ex.jpg" style="padding:0;display:inline;width: 50%;vertical-align:middle;" alt=""/><a id="equation_beta-reduction" class="anchor"></a></div>
<p>The <img src="/assets/img/cup.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> at the bottom connects the wire representing the free \(x\) variable in \(t\) to the abstraction node. After applying the first inclusion, the \(x\)-wire gets reconnected to the argument, \(u\). The result is the diagrammatic counterpart of the substitution \(t[x:=u]\).</p>
<p>So far we&#39;ve only used one side of <span class="eqref">(<a href="#adjoints">1</a>)</span>. If the first inclusion corresponds to &#40;linear&#41; \(\beta\)-reduction, the second is \(\eta\)-expansion&#33; Recall that it is given by \(t\rightarrow_\eta \lambda x. t x\) and it is not too hard to see that how this corresponds to the following inclusion:</p>
<div class="center"><img src="/assets/img/eta-expansion.jpg" style="padding:0;display:inline;width: 15%;vertical-align:middle;" alt=""/></div>
<p>I don&#39;t know if \(\eta\)-laws are a standard feature of the sharing graph/interaction net literature, but it certainly seems natural to include it here, as it constitutes one side of the adjunction between application and abstraction.</p>
<h2 id="copying_and_discarding"><a href="#copying_and_discarding" class="header-anchor">Copying and discarding</a></h2>
<p>For any preorder, we also have a form of copying \(X \rightarrow X\times X\) given by </p>
<div class="center"><img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/>\(=\{(t, (t_1, t_2)) : t \leq t_1 \text{ and } t ≤ t_2\}\).</div>
<p>For any preorder, we get a right adjoint to <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> for free:</p>
<div class="center"><img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> \(= \{((t1, t2), t) : t1 \leq t \land t2 \leq t\}\).</div>
<p>Instantiating the two inclusions in <span class="eqref">(<a href="#adjoints">1</a>)</span>, this means that</p>
<div class="center"><img src="/assets/img/adjunction-cocpy-cpy.jpg" style="padding:0;display:inline;width: 20%;vertical-align:middle;" alt=""/> \(\quad\) and \(\quad\) <img src="/assets/img/adjunction-cpy-cocpy.jpg" style="padding:0;display:inline;width: 18%;vertical-align:middle;" alt=""/></div>
<p>We need to discuss what happens when <img src="/assets/img/abs.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> or <img src="/assets/img/app.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> interact with <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> or <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/>. </p>
<p>The point of introducing these last two generators was to duplicate certain diagrams. Luckily, the following inclusions always hold in our semantics, so that we can soundly duplicate <img src="/assets/img/abs.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> or <img src="/assets/img/app.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/>, as expected:</p>
<div class="center"><img src="/assets/img/copy-abs-app.jpg" style="padding:0;display:inline;width: 60%;vertical-align:middle;" alt=""/></div>
<p>Note that this is why we needed <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/>: when <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> meets <img src="/assets/img/abs.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/>, we need some appropriate way of merging the two downward-flowing wires &#40;corresponding to \(X^{op}\)&#41; that result from this interaction, as in the inclusion on the left above.</p>
<p>Before drawing a few examples, there&#39;s one last component I have not mentioned yet: <em>discarding</em>. Sometimes we need to discard variables or entire subterms &#40;to perform garbage collection in programming language slang&#41;. Technically, a discarding operation can be defined from what we already have as </p>
<div class="center"><img src="/assets/img/del-def.jpg" style="padding:0;display:inline;width: 22%;vertical-align:middle;" alt=""/></div>
<p>but it is more convenient to introduce a special generator in our syntax, <img src="/assets/img/del.jpg" style="padding:0;display:inline;width: 2%;vertical-align:top;" alt=""/>. Like our other generators, <img src="/assets/img/del.jpg" style="padding:0;display:inline;width: 2%;vertical-align:top;" alt=""/> also has a right adjoint <img src="/assets/img/co-del.jpg" style="padding:0;display:inline;width: 2.5%;vertical-align:top;" alt=""/> so that we have the following inclusions: </p>
<div class="center"><img src="/assets/img/adjunction-del-codel.jpg" style="padding:0;display:inline;width: 50%;vertical-align:middle;" alt=""/></div>
<p><a id="adjunction_unit" class="anchor"></a> We can also delete <img src="/assets/img/abs.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> or <img src="/assets/img/app.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> as the following inclusions hold:</p>
<div class="center"><img src="/assets/img/del-abs-app.jpg" style="padding:0;display:inline;width: 55%;vertical-align:middle;" alt=""/></div>
<p>These new nodes also act as unit &#40;<em>resp.</em> counit&#41; for <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> &#40;<em>resp.</em> <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/>&#41;:</p>
<div class="center"><img src="/assets/img/unital.jpg" style="padding:0;display:inline;width: 30%;vertical-align:middle;" alt=""/></div>
<p>Finally, <img src="/assets/img/del.jpg" style="padding:0;display:inline;width: 2%;vertical-align:top;" alt=""/> and <img src="/assets/img/co-del.jpg" style="padding:0;display:inline;width: 2%;vertical-align:top;" alt=""/> get duplicated when they meet <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> and <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/>, respectively:</p>
<div class="center"><img src="/assets/img/unit-copy.jpg" style="padding:0;display:inline;width: 45%;vertical-align:middle;" alt=""/></div>
<h2 id="putting_it_all_together"><a href="#putting_it_all_together" class="header-anchor">Putting it all together</a></h2>
<p>With copying and discarding, we can extend our encoding of linear \(\lambda\)-terms to all terms, simply copying a variable with <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> when it is used multiple times or discarding it with <img src="/assets/img/del.jpg" style="padding:0;display:inline;width: 2%;vertical-align:middle;" alt=""/> when it is not used.  </p>
<p>All the inclusions we have covered so far can be interpreted as rewriting rules for our diagrams. The hope is that the resulting rewriting system is a diagrammatic implementation of \(\beta\)-reduction. As we will see, our wishes do come true sometimes, <a href="#the_problem_with_copying">but not always</a>.</p>
<p>Let&#39;s see it all at work on <a href="https://en.wikipedia.org/wiki/SKI_combinator_calculus">a few standard examples</a>:</p>
<div class="center"><img src="/assets/img/example-terms.jpg" style="padding:0;display:inline;width: 65%;vertical-align:middle;" alt=""/></div>
<p>The encoding of the static syntax is not the reason you read all this way, so let&#39;s see how the diagrammatic counterpart of reduction behaves on a simple example. It is a basic exercise to show \(SKK=I\). Here&#39;s how we prove it diagrammatically:</p>
<div class="center"><img src="/assets/img/skk-1.jpg" style="padding:0;display:inline;width: 45%;vertical-align:middle;" alt=""/> <img src="/assets/img/skk-2.jpg" style="padding:0;display:inline;width: 30%;vertical-align:middle;" alt=""/> <img src="/assets/img/skk-3.jpg" style="padding:0;display:inline;width: 50%;vertical-align:middle;" alt=""/><img src="/assets/img/skk-4.jpg" style="padding:0;display:inline;width: 50%;vertical-align:middle;" alt=""/><img src="/assets/img/skk-5.jpg" style="padding:0;display:inline;width: 45%;vertical-align:middle;" alt=""/> <img src="/assets/img/skk-6.jpg" style="padding:0;display:inline;width: 15%;vertical-align:middle;" alt=""/><img src="/assets/img/skk-7.jpg" style="padding:0;display:inline;width: 25%;vertical-align:middle;" alt=""/></div>
<p>where the inclusion labeled <strong>&#40;Lemma&#41;</strong> comes from replacing \(K\) by its definition and applying the following twice: </p>
<div class="center"><img src="/assets/img/lemma-k-app.jpg" style="padding:0;display:inline;width: 50%;vertical-align:middle;" alt=""/></div>
<p>We did not use the adjunction between <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> and <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> in this example so let&#39;s compute another &#40;useless&#41; one: \((\lambda fx. f (f x)) (\lambda x.x)\). This amounts to applying the identity twice to an argument–-this should give us back the identity&#33; Let&#39;s check that this is the case. This time I&#39;ll go a bit faster, but watch out for the third inclusion, where <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> and <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> cancel each other out:</p>
<div class="center"><img src="/assets/img/id-twice.jpg" style="padding:0;display:inline;width: 65%;vertical-align:middle;" alt=""/></div>
<p>Phew&#33; If these examples seem long an tedious that&#39;s because they are. Not that it&#39;s fun to compute normal forms in the standard \(\lambda\)-calculus, but the diagrammatic version looks even more complicated. There is a good reason for this: one of the main points of graphical encodings of the \(\lambda\)-calculus is to make substitution explicit, operating at a finer level of granularity in order to keep track of resources more precisely. The thing is, on its own, the \(\lambda\)-calculus is too abstract to constitute a concrete model of computation. Even with a fixed reduction strategy &#40;say, call-by-value&#41; a single \(\beta\)-reduction step requires a global substitution of an argument for all occurrences of a bound variable inside the body of a term. This substitution cannot be implemented in constant time in general on a concrete model of computation, like a Turing machine or your actual physical computer. On the other hand, if you take a closer look at the diagrams above, you&#39;ll notice that, at each step, we only perform local rewrites, operating in constant time and space. Another advantage is that non-overlapping rewrites can be performed in parallel.</p>
<p>So what&#39;s the catch?</p>
<p>Well, unfortunately the naive procedure we&#39;ve been using is not a refinement of \(\beta\)-reduction. The issue lies with the interaction of <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/> and <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:top;" alt=""/>.</p>
<h2 id="the_problem_with_copying"><a href="#the_problem_with_copying" class="header-anchor">The problem with copying</a></h2>
<p>While we stay within the safe haven of the linear \(\lambda\)-calculus, the diagrammatic reduction procedure behaves exactly as its symbolic counterpart. But when we introduce copying, things get a lot more complicated: the inclusions from the two adjunctions above do not behave as \(\beta\)-reduction in general. </p>
<p>To understand the problem, notice that, in our strategy so far, if there are several occurrences of \(x\) in \(t\),  when we reduce the expression \((\lambda x.t) u\), we will copy \(u\) by duplicating each of its components progressively. This might include duplicating <img src="/assets/img/abs.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> nodes, creating <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> nodes that will need to be eliminated later when they encounter their <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> counterparts. However, if the copied term \(u\) itself contains copying nodes, things can go wrong.</p>
<p>Let&#39;s see what the problem is on an example. Take \((\lambda x g. (g x) x)(\lambda f x. f (f x))\). Diagrammatically, the first few steps of the reduction process go as follows:</p>
<div class="center"><img src="/assets/img/copy-pb.jpg" style="padding:0;display:inline;width: 57%;vertical-align:middle;" alt=""/><img src="/assets/img/copy-pb-2.jpg" style="padding:0;display:inline;width: 57%;vertical-align:middle;" alt=""/></div>
<p>The last diagram illustrates the core of the issue: when the <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> produced by copying the first abstraction node in \((\lambda x g. (g x) x)\) meets the copying node in the same term, they should duplicate each other instead of canceling out.</p>
<p>In summary, there are diagrams encoding well-formed \(\lambda\)-terms that we cannot copy. As I said earlier, this arises whenever we copy a term that itself contains a <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> – in this case, those <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> nodes generated by copying abstraction nodes should be duplicated when they meet <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> nodes instead of the two canceling out. Diagrammatically, we would like:</p>
<div class="center"><img src="/assets/img/cocopy-copy.jpg" style="padding:0;display:inline;width: 25%;vertical-align:middle;" alt=""/></div>
<p>Not all is lost, however. Luckily for us, the corresponding inclusion holds in our chosen semantics. So where&#39;s the problem? We can just add it to our list of allowed rewrite rules and carry on our business as usual. Unfortunately, if we apply these inclusions haphazardly, two different choices may lead to different diagrams – how do we know which one is the right one?<sup id="fnref:3"><a href="#fndef:3" class="fnref">[3]</a></sup></p>
<p>We now have to choose which rule to apply any time a <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> meets a <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/>, following some specific strategy. This is a well-known problem in the literature on sharing graphs/interaction nets. There are different options to deal with it. </p>
<ul>
<li><p>Some strategies involve keeping track of nesting of subterms. One way to do this is to introduce a notion of level and annotate nodes with the level at which they originate &#40;as I did in the example above&#41;. Then, when <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> and <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> from the same level interact, they cancel each other out, and when they belong to different levels, they duplicate each other. This requires a significant amount of bookkeeping. An equivalent implementation introduces global features, called <em>boxes</em> which enclose subterms, delimiting the level at which they live. Stefano Guerrini&#39;s <a href="https://www.sciencedirect.com/science/article/pii/S1571066105050164">gentle introduction to sharing graphs</a>  explains this. </p>
</li>
<li><p>Alternatively, it is possible to determinise the rewriting strategy by keeping track of a token that moves around the graph and applies rewrite rules only where the token is located. This is <a href="https://link.springer.com/chapter/10.1007/11417170_28">the approach taken by François-Régis Sinot</a>.</p>
</li>
<li><p>Another approach sidesteps the problem by disallowing terms that do not follow a form of syntactic stratification &#40;if you&#39;re looking for the relevant keywords, they are terms typeable in <em>elementary linear logic</em>, a form of substructural logic with restricted copying, whose cut elimination procedure is guaranteed to terminate in elementary time in the size of terms&#41;.</p>
</li>
<li><p>Finally, the more radical approach is to accept that the correspondence between diagrams and terms is not perfect, and look for another syntactic encoding. What we have here is a Turing-complete graph rewriting system, so we are free to cook up any encoding of the \(\lambda\)-calculus we like, just like we could encode it on a Turing machine or a register machine. Luckily, there are clever encodings that manage to stay close to the one we&#39;ve seen here. For example, <a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi&#61;10.1.1.22.9699">Ian Mackie and Jorge Sousa Pinto&#39;s translation</a>, which reproduce features of the encoding of \(\lambda\)-terms as linear logic proofs<sup id="fnref:4"><a href="#fndef:4" class="fnref">[4]</a></sup>, is not too difficult to understand. </p>
</li>
</ul>
<p>Coming back to our string diagrammatic interpretation, one nice feature is that the problem with copying acquires semantic content. Let me explain. We have two different inclusions to deal with the composite <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/>;<img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/>. It turns out that these two possible choices can themselves be ordered:</p>
<div class="center"><img src="/assets/img/cocopy-copy-dup-cancel.jpg" style="padding:0;display:inline;width: 40%;vertical-align:middle;" alt=""/></div>
<p>This can be seen as a consequence of the adjunction between <img src="/assets/img/del.jpg" style="padding:0;display:inline;width: 2%;vertical-align:top;" alt=""/>and <img src="/assets/img/co-del.jpg" style="padding:0;display:inline;width: 2.25%;vertical-align:top;" alt=""/>:</p>
<div class="center"><img src="/assets/img/copy-cocopy-cancel-proof.jpg" style="padding:0;display:inline;width: 58%;vertical-align:middle;" alt=""/></div>
<p>So, if we always choose to duplicate <img src="/assets/img/co-copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> and <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/>, we do not lose any semantic information. Of course, to recover a valid \(\lambda\)-term we will need to disconnect some wires <em>eventually</em>, using the second inclusion. This means that we can always postpone the choice of which wires to disconnect until the end. I found this surprising. Note that there is a space-time trade-off in this choice, as constantly duplicating nodes will increase the size of the diagram exponentially. In a way, we would be keeping track of all possible reductions, only committing to a specific form when disconnecting enough wires to recover a well-formed \(\lambda\)-term, <em>i.e.</em> a diagram made only from <img src="/assets/img/abs.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/>, <img src="/assets/img/app.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/>, <img src="/assets/img/copy.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/> and <img src="/assets/img/cup.jpg" style="padding:0;display:inline;width: 4%;vertical-align:middle;" alt=""/>.</p>
<h2 id="what_is_x"><a href="#what_is_x" class="header-anchor">What is \(X\)?</a></h2>
<p>As we saw, if we can encode any \(\lambda\)-term as a string diagram, we can also draw diagrams that do not correspond to any term. In fact, some of these may appear during the reduction process, because diagrammatic reduction is more fined-grained than \(\beta\)-reduction. This is a feature and a bug, depending on how you look at it. A feature, because the point of introducing diagrams is to keep track of resources, via explicit copying and discarding. A bug, because the increased granularity needs to be approached carefully if we really want to mimic \(\beta\)-reduction. </p>
<p>To even draw these diagrams we needed our generators to satisfy certain properties. You may be wondering what these mean, semantically. Of course, you can approach the problem purely formally and say that these conditions are just what you need to implement \(\beta\)-reduction. But here&#39;s how I think about \(X\) in order to make all the required inclusions true. We can construct \(X\) as the set of downward-closed sets of \(\Lambda\). This is the free join semi-lattice over \(\Lambda\). Constructed in this way, the elements of \(X\) that are not principal, <em>i.e.</em> not of the form \(\{u\,: u\leq t\}\) for some term \(t\), can be thought of as generated by some set of terms. In other words, we can think of the elements of \(X\) as types&#33; This might seem a bit strange because, from this point of view, terms are also types. But this is not so crazy if we view both types and terms as <em>behaviours</em> with varying degrees of nondeterminism. In other words, for two elements of \(X\), \(x\leq y\) can be read as \(x\) implements/refines/realises the specification \(y\). With this in mind, we can think of diagrams \(1\rightarrow X\) &#40;with a single outgoing wire&#41; that do not encode a \(\lambda\)-term as types or specifications that are not fully deterministic. I&#39;m not entirely sure what this means, but it sounds profound.</p>
<h1 id="references"><a href="#references" class="header-anchor">References</a></h1>
<ul>
<li><p><a href="https://doi.org/10.1016/j.entcs.2005.04.020">Sharing Implementations of Graph Rewriting Systems</a>, by Stefano Guerrini.</p>
</li>
<li><p><a href="https://link.springer.com/chapter/10.1007/11417170_28">Call-by-Name and Call-by-Value as Token-Passing Interaction Nets</a>, by François-Régis Sinot.</p>
</li>
<li><p><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi&#61;10.1.1.22.9699">Compiling the lambda-calculus into Interaction Combinators</a>, by Ian Mackie &amp; Jorge Sousa Pinto .</p>
</li>
</ul>
<p><table class="fndef" id="fndef:1">
    <tr>
        <td class="fndef-backref"><a href="#fnref:1">[1]</a></td>
        <td class="fndef-content">Diagrams should be read flowing from bottom to top for composition, and from left to right for the monoidal product. </td>
    </tr>
</table>
 <table class="fndef" id="fndef:2">
    <tr>
        <td class="fndef-backref"><a href="#fnref:2">[2]</a></td>
        <td class="fndef-content">If you&#39;re already familiar with sharing graphs or interaction nets, you will notice that, unlike those, the edges of our diagrams are directed. Diagrams for relational profunctors can be drawn undirected iff \(X=X^{op}\) iff the underlying order is also symmetric, <em>i.e.</em> if it is the equality over \(X\). However, it is not clear in this case that abstraction can be defined over such an \(X\). Is this related to how there are no good set-theoretic models for the untyped \(\lambda\)-calculus and one needs to turn to more exotic constructions, like those of domain theory, for instance? Perhaps someone else can enlighten me here.</td>
    </tr>
</table>
 <table class="fndef" id="fndef:3">
    <tr>
        <td class="fndef-backref"><a href="#fnref:3">[3]</a></td>
        <td class="fndef-content">I originally wanted to write that the resulting rewriting system was no longer confluent. While technically true, this is also the case of the previous system, if we include the use of inclusions coming from the adjunction between <img src="/assets/img/del.jpg" style="padding:0;display:inline;width: 2%;vertical-align:top;" alt=""/> and <img src="/assets/img/co-del.jpg" style="padding:0;display:inline;width: 2.5%;vertical-align:top;" alt=""/>.</td>
    </tr>
</table>
 <table class="fndef" id="fndef:4">
    <tr>
        <td class="fndef-backref"><a href="#fnref:4">[4]</a></td>
        <td class="fndef-content">The correspondence with linear logic is a recurring theme in this area. The boxes/levels I&#39;ve mentioned are also a way of encoding the <em>exponentials</em> – the modality that controls access to copying and deleting in linear logic.</td>
    </tr>
</table>
</p>
<div class="page-foot">
  <div class="copyright">
    &copy; Robin Piedeleu. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div><!-- CONTENT ENDS HERE -->
    </div>  <!-- div: content container -->
    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
  </body>
</html>
